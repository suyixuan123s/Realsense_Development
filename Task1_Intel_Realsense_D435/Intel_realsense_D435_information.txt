# 理想范围 0.3m to 3m


# Intel RealSense D435 工作原理
# 左右红外相机（接收器）
# 红外灰度图像：RealSense D435 使用左右两个红外相机（IR 摄像头）来采集深度数据。由于它们相互间有一定的基线（距离），这使得系统能够通过比较图像中的视差来估算每个像素的深度信息。这些相机捕捉的图像通常是 灰度图像，即只包含深度信息，而不包含颜色信息。
# 视差计算：左右红外相机拍摄的图像之间的像素差异（视差）用于计算场景中物体的距离。通过对这两个图像中的相同特征点进行匹配，系统可以推算出每个点的深度，从而生成深度图。
# 红外点阵发射器（红外散斑）
# 功能：中间的 红外点阵发射器 通常用于生成 红外光散斑，这是一种已知模式的红外光，通过投射到物体表面，辅助深度计算。点阵发射器的作用类似于一种 补光灯，在低光或无光环境下帮助相机更好地捕捉深度数据。
# 点云生成
# 点云（Point Cloud）：通过左右红外相机捕获的深度数据和红外点阵发射器的辅助光源，RealSense D435 可以生成一个 三维点云，这个点云表示了物体的三维空间坐标，通常每个点都具有 (x, y, z) 坐标，且与场景中的物体表面相对应。
# 点云数据：这个三维点云数据可以用于物体识别、三维建模、环境扫描、手势识别等各种高级视觉任务。
# RGB相机
# 彩色图像采集：最右侧的 RGB 相机 负责采集场景的 彩色图像。RGB 摄像头和红外传感器（立体视觉和红外点阵发射器）配合工作，通常会提供 彩色视频流，并与深度流进行对齐，得到 彩色深度图。这个过程可以通过硬件或软件实现图像与深度信息的 对齐（alignment），即将每个深度图中的点与对应的彩色像素匹配。
#
# 使用环境	Indoor/Outdoor
# 图像传感器技术	Global Shutter
# 理想范围	0.3m to 3m
#    深度
#
# 深度技术	立体
# 深度视场（FOV）	87°×58°
# 最大分辨率下的最小深度距离（Min-Z）	~28cm
# 深度输出分辨率	Up to 1280 × 720
# 深度精度	在2米处<2%
# 深度帧率	Up to 90 fps
#   RGB
#
# RGB画面分辨率	1920 × 1080
# RGB帧速率	30 fps
# RGB传感器技术	Rolling Shutter
# RGB传感器FOV（H×V）	69°  × 42°
# RGB传感器分辨率	2 MP
#   主要组件
#
# 相机模块	英特尔RealSense模块D430+RGB摄像头
# 视觉处理器板	英特尔RealSense视觉处理器D4
#   物理
#
# 外形因素	相机周边设备
# 长×深×高	90 mm × 25 mm × 25 mm
# 连接器	USB-C3.1  Gen 1
# 安装机制
# 一个1/4-20 UNC螺纹安装点
#
# 两个M4螺纹安装点


#
# REALSENSE使用的是结构光的方案。正面的四个摄像头，从左向右以次是左红外相机，红外点阵投射仪，右红外相机，和RGB相机。
#
# 结构光的原理是：在激光器外放置一个光栅，激光通过光栅进行投射成像时会发生折射，从而使得激光最终在物体表面上的落点产生位移。当物体距离激光投射器比较近的时候，折射而产生的位移就较小；当物体距离较远时，折射而产生的位移也就会相应的变大。这时使用一个摄像头来检测采集投射到物体表面上的图样，通过图样的位移变化，就能用算法计算出物体的位置和深度信息，进而复原整个三维空间。
#
# 最高 1280×720 双目深度分辨率
# 最高 1920×1080 RGB 分辨率
# 最高 90 FPS 深度视频流。深度流与普通 RGB 视频流类似，只不过每个像素点的值不再是 RGB 或灰度值，而是物体相对于相机的距离。
# 只能对相同帧率的 RGB 与深度视频流做同步设置
# 双目 baseline 为 50 mm
# 深度探测范围 0.2 m ~ 10 m
# 深度坐标系以左侧相机为中心（下图中 centerline of 1/4-20 是指三脚架螺丝空的中心）